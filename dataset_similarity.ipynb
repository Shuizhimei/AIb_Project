{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this file, you need to load datasets from `sharedata/data_for_compute_similarity/data` into your `data` folder, where there are 5 datasets.\n",
    "\n",
    "that is, you may use the command `cp -r /shareddata/data_for_compute_similarity/data/ .`\n",
    "\n",
    "Additionally, you also need to load clip model by the command `cp -r /data/lab/STA303-Assignment02/clip/ .`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deal with the mini-imagenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义数据集目录\n",
    "# dataset_dir = \"data/mini-imagenet/images/\"\n",
    "\n",
    "# os.remove(\"data/mini-imagenet/images/.DS_Store\")\n",
    "# # 遍历数据集目录下的所有图片文件\n",
    "# for filename in os.listdir(dataset_dir):\n",
    "#     if filename.endswith(\".jpg\"):\n",
    "#         # 除去文件名的后四位数字\n",
    "#         class_id = filename[0:9]\n",
    "        \n",
    "#         # 构建目标类别目录\n",
    "#         target_class_dir = os.path.join(dataset_dir, class_id)\n",
    "#         os.makedirs(target_class_dir, exist_ok=True)\n",
    "        \n",
    "#         # 构建源文件路径和目标文件路径\n",
    "#         source_path = os.path.join(dataset_dir, filename)\n",
    "#         target_path = os.path.join(target_class_dir, filename)\n",
    "        \n",
    "#         # 移动文件到目标类别目录\n",
    "#         shutil.move(source_path, target_path)\n",
    "\n",
    "# print(\"操作完成。\")\n",
    "# tmp = os.listdir(dataset_dir)\n",
    "# print(len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the training set and testing set (`Plant disease` and `standford cars`) to the directory `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_dataset(dataset_dir):\n",
    "#     # 定义训练集和测试集目录\n",
    "#     train_dir = os.path.join(dataset_dir, \"train\")\n",
    "#     test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "#     # 获取训练集和测试集中的类别\n",
    "#     train_classes = set(os.listdir(train_dir))\n",
    "#     test_classes = set(os.listdir(test_dir))\n",
    "\n",
    "#     # 检查训练集和测试集中的类别是否一致\n",
    "#     if train_classes != test_classes:\n",
    "#         raise ValueError(\"训练集和测试集中的类别不一致，请检查数据集。\")\n",
    "\n",
    "#     for subset_dir in [train_dir, test_dir]:\n",
    "#         for class_name in os.listdir(subset_dir):\n",
    "#             class_dir = os.path.join(subset_dir, class_name)\n",
    "            \n",
    "#             # 遍历类别目录下的所有图片文件\n",
    "#             for filename in os.listdir(class_dir):\n",
    "#                 if filename.endswith(\".jpg\"):\n",
    "#                     # 构建目标类别目录\n",
    "#                     target_class_dir = os.path.join(dataset_dir, \"images\", class_name)\n",
    "#                     os.makedirs(target_class_dir, exist_ok=True)\n",
    "                    \n",
    "#                     # 构建源文件路径和目标文件路径\n",
    "#                     source_path = os.path.join(class_dir, filename)\n",
    "#                     target_path = os.path.join(target_class_dir, filename)\n",
    "                    \n",
    "#                     # 移动文件到目标类别目录\n",
    "#                     shutil.move(source_path, target_path)\n",
    "\n",
    "\n",
    "#     shutil.rmtree(train_dir)\n",
    "#     shutil.rmtree(test_dir)\n",
    "\n",
    "#     print(\"操作完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_dataset('data/Plant_disease/')\n",
    "# merge_dataset('data/stanford_cars/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from clip import clip\n",
    "import pickle\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUAL_BACKBONE = 'RN50' # RN50, ViT-B/32, ViT-B/16\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, transform = clip.load(VISUAL_BACKBONE, device=device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## try one image \n",
    "# image_path = \"data/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "# image_tensor = preprocess_image(image_path)\n",
    "# vec_features = model.encode_image(image_tensor)\n",
    "# print(vec_features)\n",
    "# print(vec_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Sim(D_B,D_N) = exp(-\\alpha ~EMD(D_B,D_N))$\n",
    "\n",
    "where \n",
    "$EMD(D_B,D_N) = \\frac{\\sum_{i \\in C_B, ~j \\in C_N}{f_{i,j}~d_{i,j}}}{\\sum_{i \\in C_B, ~j \\in C_N}{f_{i,j}}},~~\\alpha ~\\text{is typically set to} ~ 0.01$\n",
    "\n",
    "where $d_{i,j} = \\Vert p_i-p_j \\Vert_2 $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUB\n",
    "CUB_path = 'data/CUB_200_2011/images/'\n",
    "\n",
    "# Stanford Cars\n",
    "Cars_path = 'data/stanford_cars/images/'\n",
    "\n",
    "# EuroSAT\n",
    "EuroSAT_path = 'data/EuroSAT_RGB/'\n",
    "\n",
    "# Plant disease\n",
    "Plant_path = 'data/Plant_disease/images'\n",
    "\n",
    "# mini-imagenet\n",
    "mini_path = 'data/mini-imagenet/images/'\n",
    "\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算源域的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [06:48<1:01:18, 40.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(class_i):\n\u001b[1;32m     15\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_i, image_name)\n\u001b[0;32m---> 16\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m image_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m     p_i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_image(image_tensor)\n",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path):\n\u001b[1;32m      2\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 分别得到两个数据集的标签集\n",
    "mini_class = os.listdir(mini_path)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    # 遍历第一个数据集的标签\n",
    "    mini_vectorlist = [] \n",
    "    for i in tqdm(mini_class):   \n",
    "        ##* 对于 dataset1 的 i类 图像， 提取出平均特征 p_i\n",
    "        class_i = os.path.join(mini_path, i)\n",
    "        \n",
    "        p_i = 0\n",
    "        \n",
    "        # 遍历类别下的每张图片\n",
    "        for image_name in os.listdir(class_i):\n",
    "            image_path = os.path.join(class_i, image_name)\n",
    "            image_tensor = preprocess_image(image_path)\n",
    "            image_tensor = image_tensor.to(device)\n",
    "            p_i += model.encode_image(image_tensor)\n",
    "        \n",
    "        p_i = p_i / len(os.listdir(class_i)) \n",
    "\n",
    "        mini_vectorlist.append(p_i)\n",
    "\n",
    "\n",
    "# 创建一个文件夹叫vectorlist，如果它不存在的话\n",
    "vectorlist_folder = 'vectorlist_for_similarity'\n",
    "os.makedirs(vectorlist_folder, exist_ok=True)\n",
    "\n",
    "# 保存 mini_vectorlist\n",
    "vectorlist_file_path = os.path.join(vectorlist_folder, 'mini_vectorlist.pkl')\n",
    "with open(vectorlist_file_path, 'wb') as f:\n",
    "    pickle.dump(mini_vectorlist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 mini_vectorlist\n",
    "vectorlist_file_path = 'vectorlist/mini_vectorlist.pkl'\n",
    "with open(vectorlist_file_path, 'rb') as f:\n",
    "    loaded_mini_vectorlist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "源域与数据集之间的similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#源域与数据集之间的similarity\n",
    "def similarity_withSource(target_path):\n",
    "    # 分别得到 target 数据集的标签列表\n",
    "    target_class = os.listdir(target_path)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 遍历第二个数据集的标签\n",
    "        target_vectorlist = []\n",
    "        for j in tqdm(target_class):\n",
    "            ##* 对于 target_path 的 第j类 图像，提取出平均特征 p_j\n",
    "            class_j = os.path.join(target_path, j)\n",
    "            \n",
    "            p_j = 0\n",
    "            # 遍历类别下的每张图片\n",
    "            for image_name in os.listdir(class_j):\n",
    "                image_path = os.path.join(class_j, image_name)\n",
    "                image_tensor = preprocess_image(image_path)\n",
    "                image_tensor = image_tensor.to(device)\n",
    "                p_j += model.encode_image(image_tensor)\n",
    "            \n",
    "            p_j = p_j / len(os.listdir(class_j))    \n",
    "            target_vectorlist.append(p_j)        \n",
    "            \n",
    "        # 保存 mini_vectorlist\n",
    "        \n",
    "        # 使用 split 方法获取目标字符串\n",
    "        start_index = target_path.find('data/') + len('data/')\n",
    "        end_index = target_path.find('/', start_index)\n",
    "        result_string = target_path[start_index:end_index]\n",
    "        \n",
    "        vectorlist_file_path = os.path.join(\"vectorlist_for_similarity\", result_string,'_vectorlist.pkl')\n",
    "        with open(vectorlist_file_path, 'wb') as f:\n",
    "            pickle.dump(target_vectorlist, f)\n",
    "    \n",
    "        # 创建 权重矩阵\n",
    "        weight_matrix = np.ones((len(loaded_mini_vectorlist),len(target_vectorlist)))  \n",
    "        weight_matrix = weight_matrix/np.sum(weight_matrix)\n",
    "         \n",
    "        # 计算\n",
    "        EMD = 0\n",
    "        for i in range(len(loaded_mini_vectorlist)):\n",
    "            for j in range(len(target_vectorlist)):\n",
    "                \n",
    "                ##* 将两个求二范数  d_ij\n",
    "                EMD += weight_matrix[i][j] * torch.norm(loaded_mini_vectorlist[i] - target_vectorlist[j], p=2)\n",
    "\n",
    "    return math.e ** (-1*alpha*EMD)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任意两个数据集之间的similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任意两个数据集之间的similarity\n",
    "\n",
    "# def similarity(dataset1,dataset2):\n",
    "#     # 分别得到两个数据集的标签列表\n",
    "#     label_class1 = os.listdir(dataset1)\n",
    "#     label_class2 = os.listdir(dataset2)\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "#         # 遍历第一个数据集的标签\n",
    "#         dataset1_vectorlist = [] \n",
    "#         for i in tqdm(label_class1):   \n",
    "#             ##* 对于 dataset1 的 i类 图像， 提取出平均特征 p_i\n",
    "#             class_i = os.path.join(dataset1, i)\n",
    "            \n",
    "#             p_i = 0\n",
    "            \n",
    "#             # 遍历类别下的每张图片\n",
    "#             for image_name in os.listdir(class_i):\n",
    "#                 image_path = os.path.join(class_i, image_name)\n",
    "#                 image_tensor = preprocess_image(image_path)\n",
    "#                 image_tensor = image_tensor.to(device)\n",
    "#                 p_i += model.encode_image(image_tensor)\n",
    "            \n",
    "#             p_i = p_i / len(os.listdir(class_i)) \n",
    "\n",
    "#             dataset1_vectorlist.append(p_i)\n",
    "            \n",
    "#         # 遍历第二个数据集的标签\n",
    "#         dataset2_vectorlist = []\n",
    "#         for j in tqdm(label_class2):\n",
    "#             ##* 对于 dataset2 的 第j类 图像，提取出平均特征 p_j\n",
    "#             class_j = os.path.join(dataset2, j)\n",
    "            \n",
    "#             p_j = 0\n",
    "#             # 遍历类别下的每张图片\n",
    "#             for image_name in os.listdir(class_j):\n",
    "#                 image_path = os.path.join(class_j, image_name)\n",
    "#                 image_tensor = preprocess_image(image_path)\n",
    "#                 image_tensor = image_tensor.to(device)\n",
    "#                 p_j += model.encode_image(image_tensor)\n",
    "            \n",
    "#             p_j = p_j / len(os.listdir(class_j))    \n",
    "#             dataset2_vectorlist.append(p_j)        \n",
    "            \n",
    "            \n",
    "#         # 创建 权重矩阵\n",
    "#         weight_matrix = np.ones((len(label_class1),len(label_class2)))  \n",
    "#         weight_matrix = weight_matrix/np.sum(weight_matrix)\n",
    "         \n",
    "#         # 计算\n",
    "#         EMD = 0\n",
    "#         for i in range(len(dataset1_vectorlist)):\n",
    "#             for j in range(len(dataset2_vectorlist)):\n",
    "                \n",
    "#                 ##* 将两个求二范数  d_ij\n",
    "#                 EMD += weight_matrix[i][j] * torch.norm(dataset1_vectorlist[i] - dataset2_vectorlist[j], p=2)\n",
    "\n",
    "#     return math.e ** (-1*alpha*EMD)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUB\n",
    "# CUB_path = 'data/CUB_200_2011/images/'\n",
    "\n",
    "# # Stanford Cars\n",
    "# Cars_path = 'data/stanford_cars/images/'\n",
    "\n",
    "# # EuroSAT\n",
    "# EuroSAT_path = 'data/EuroSAT_RGB/'\n",
    "\n",
    "# # Plant disease\n",
    "# Plant_path = 'data/Plant_disease/images'\n",
    "\n",
    "# # mini-imagenet\n",
    "# mini_path = 'data/mini-imagenet/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the hierarchy: `data_dir`->`(class1, class2, ...)`->`(image1.jpg, image2.jpg)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_withSource(CUB_path)\n",
    "similarity_withSource(Cars_path)\n",
    "similarity_withSource(EuroSAT_path)\n",
    "similarity_withSource(Plant_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
